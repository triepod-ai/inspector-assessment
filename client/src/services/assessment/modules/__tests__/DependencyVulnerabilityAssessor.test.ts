/**
 * DependencyVulnerabilityAssessor Test Suite
 * Tests for Issue #193 - npm/yarn/pnpm audit vulnerability detection
 *
 * Test categories:
 * 1. Package manager detection
 * 2. Audit command execution
 * 3. npm audit output parsing
 * 4. yarn audit output parsing
 * 5. pnpm audit output parsing
 * 6. Score penalty calculation
 * 7. Status determination
 * 8. Skip scenarios
 * 9. Error handling
 */

import { DependencyVulnerabilityAssessor } from "../DependencyVulnerabilityAssessor";
import {
  createMockAssessmentContext,
  createMockAssessmentConfig,
} from "@/test/utils/testUtils";
import { AssessmentContext } from "../../AssessmentOrchestrator";
import * as childProcess from "child_process";
import * as fs from "fs";
import * as path from "path";

// Mock child_process.exec
jest.mock("child_process", () => ({
  exec: jest.fn(),
}));

// Mock fs.existsSync
jest.mock("fs", () => ({
  ...jest.requireActual("fs"),
  existsSync: jest.fn(),
}));

const mockExec = childProcess.exec as unknown as jest.Mock;
const mockExistsSync = fs.existsSync as unknown as jest.Mock;

describe("DependencyVulnerabilityAssessor", () => {
  let assessor: DependencyVulnerabilityAssessor;
  let mockContext: AssessmentContext;

  beforeEach(() => {
    const config = createMockAssessmentConfig({
      enableExtendedAssessment: true,
      enableSourceCodeAnalysis: true,
      assessmentCategories: {
        dependencyVulnerability: true,
      },
    });
    assessor = new DependencyVulnerabilityAssessor(config);
    mockContext = createMockAssessmentContext({ config });
    jest.clearAllMocks();
  });

  // ============================================
  // Section 1: Skip Scenarios
  // ============================================

  describe("skip scenarios", () => {
    it("should skip when no sourceCodePath is provided", async () => {
      mockContext.sourceCodePath = undefined;

      const result = await assessor.assess(mockContext);

      expect(result.skipped).toBe(true);
      expect(result.skipReason).toContain("No source code path");
      expect(result.status).toBe("NEED_MORE_INFO");
      expect(result.hasPackageManager).toBe(false);
    });

    it("should skip when no lock file is found", async () => {
      mockContext.sourceCodePath = "/some/project/path";
      mockExistsSync.mockReturnValue(false);

      const result = await assessor.assess(mockContext);

      expect(result.skipped).toBe(true);
      expect(result.skipReason).toContain("No package-lock.json");
      expect(result.status).toBe("NEED_MORE_INFO");
      expect(result.hasPackageManager).toBe(false);
    });
  });

  // ============================================
  // Section 2: Package Manager Detection
  // ============================================

  describe("package manager detection", () => {
    it("should detect npm from package-lock.json", async () => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );

      // Mock successful audit with no vulnerabilities
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: '{"vulnerabilities":{}}' });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.packageManager).toBe("npm");
      expect(result.auditInfo.lockFileType).toBe("package-lock.json");
    });

    it("should detect yarn from yarn.lock", async () => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("yarn.lock"),
      );

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout:
              '{"type":"auditSummary","data":{"vulnerabilities":{"critical":0,"high":0,"moderate":0,"low":0}}}',
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.packageManager).toBe("yarn");
      expect(result.auditInfo.lockFileType).toBe("yarn.lock");
    });

    it("should detect pnpm from pnpm-lock.yaml", async () => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("pnpm-lock.yaml"),
      );

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: '{"advisories":{}}' });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.packageManager).toBe("pnpm");
      expect(result.auditInfo.lockFileType).toBe("pnpm-lock.yaml");
    });

    it("should prefer npm over yarn when both exist", async () => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockReturnValue(true); // All lock files exist

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: '{"vulnerabilities":{}}' });
        },
      );

      const result = await assessor.assess(mockContext);

      // npm is checked first in LOCK_FILE_MAP order
      expect(result.auditInfo.packageManager).toBe("npm");
    });
  });

  // ============================================
  // Section 3: npm Audit Output Parsing
  // ============================================

  describe("npm audit parsing", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );
    });

    it("should parse npm audit with no vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("PASS");
      expect(result.totalAdvisories).toBe(0);
      expect(result.vulnerabilities).toEqual({
        critical: 0,
        high: 0,
        moderate: 0,
        low: 0,
      });
    });

    it("should parse npm audit with vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {
                lodash: {
                  name: "lodash",
                  severity: "high",
                  via: [{ title: "Prototype Pollution" }],
                  nodes: ["lodash"],
                  fixAvailable: true,
                },
                minimist: {
                  name: "minimist",
                  severity: "moderate",
                  via: ["Prototype Pollution via constructor"],
                  nodes: ["minimist"],
                  fixAvailable: false,
                },
              },
              metadata: {
                vulnerabilities: { critical: 0, high: 1, moderate: 1, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("NEED_MORE_INFO");
      expect(result.totalAdvisories).toBe(2);
      expect(result.vulnerabilities.high).toBe(1);
      expect(result.vulnerabilities.moderate).toBe(1);
      expect(result.findings).toHaveLength(2);
      expect(result.findings[0].packageName).toBe("lodash");
      expect(result.findings[0].severity).toBe("high");
      expect(result.findings[0].fixAvailable).toBe(true);
    });

    it("should handle npm audit exit code 1 (vulnerabilities found)", async () => {
      const auditOutput = JSON.stringify({
        vulnerabilities: {
          axios: {
            name: "axios",
            severity: "critical",
            via: ["RCE"],
            nodes: ["axios"],
            fixAvailable: true,
          },
        },
        metadata: {
          vulnerabilities: { critical: 1, high: 0, moderate: 0, low: 0 },
        },
      });

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (
            err: { code: number; stdout: string },
            result: null,
          ) => void,
        ) => {
          // npm audit exits with code 1 when vulnerabilities found
          callback({ code: 1, stdout: auditOutput }, null);
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.auditCompleted).toBe(true);
      expect(result.status).toBe("FAIL");
      expect(result.vulnerabilities.critical).toBe(1);
    });
  });

  // ============================================
  // Section 4: yarn Audit Output Parsing
  // ============================================

  describe("yarn audit parsing", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("yarn.lock"),
      );
    });

    it("should parse yarn audit newline-delimited JSON", async () => {
      const yarnOutput = [
        '{"type":"auditAdvisory","data":{"resolution":{"id":1,"path":"lodash","dev":false},"advisory":{"module_name":"lodash","severity":"high","title":"Prototype Pollution","cves":["CVE-2021-23337"]}}}',
        '{"type":"auditSummary","data":{"vulnerabilities":{"info":0,"low":0,"moderate":0,"high":1,"critical":0},"dependencies":100}}',
      ].join("\n");

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: yarnOutput });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.packageManager).toBe("yarn");
      expect(result.totalAdvisories).toBe(1);
      expect(result.vulnerabilities.high).toBe(1);
      expect(result.findings[0].packageName).toBe("lodash");
      expect(result.findings[0].cve).toBe("CVE-2021-23337");
    });
  });

  // ============================================
  // Section 5: pnpm Audit Output Parsing
  // ============================================

  describe("pnpm audit parsing", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("pnpm-lock.yaml"),
      );
    });

    it("should parse pnpm audit JSON", async () => {
      const pnpmOutput = JSON.stringify({
        advisories: {
          1234: {
            module_name: "express",
            severity: "moderate",
            title: "Open Redirect",
            cves: ["CVE-2022-12345"],
            patched_versions: ">=4.18.0",
            findings: [{ version: "4.17.1", paths: ["express"] }],
          },
        },
        metadata: {
          vulnerabilities: { critical: 0, high: 0, moderate: 1, low: 0 },
        },
      });

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: pnpmOutput });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.packageManager).toBe("pnpm");
      expect(result.totalAdvisories).toBe(1);
      expect(result.vulnerabilities.moderate).toBe(1);
      expect(result.findings[0].packageName).toBe("express");
      expect(result.findings[0].fixedIn).toBe(">=4.18.0");
    });
  });

  // ============================================
  // Section 6: Score Penalty Calculation
  // ============================================

  describe("score penalty calculation", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );
    });

    it("should calculate correct penalty for critical vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {
                pkg1: { severity: "critical", via: ["RCE"], nodes: ["pkg1"] },
                pkg2: { severity: "critical", via: ["RCE"], nodes: ["pkg2"] },
              },
              metadata: {
                vulnerabilities: { critical: 2, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      // 2 critical × -10 = -20
      expect(result.scorePenalty).toBe(-20);
    });

    it("should calculate mixed severity penalty correctly", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 1, high: 2, moderate: 3, low: 4 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      // 1×(-10) + 2×(-5) + 3×(-2) + 4×(-1) = -10 + -10 + -6 + -4 = -30
      expect(result.scorePenalty).toBe(-30);
    });

    it("should return 0 penalty for no vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.scorePenalty).toBe(0);
    });
  });

  // ============================================
  // Section 7: Status Determination
  // ============================================

  describe("status determination", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );
    });

    it("should return FAIL for critical vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 1, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("FAIL");
    });

    it("should return NEED_MORE_INFO for high vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 1, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("NEED_MORE_INFO");
    });

    it("should return NEED_MORE_INFO for moderate vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 0, moderate: 1, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("NEED_MORE_INFO");
    });

    it("should return PASS for only low vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 0, moderate: 0, low: 5 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("PASS");
    });

    it("should return PASS for no vulnerabilities", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {},
              metadata: {
                vulnerabilities: { critical: 0, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.status).toBe("PASS");
    });
  });

  // ============================================
  // Section 8: Error Handling
  // ============================================

  describe("error handling", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );
    });

    it("should handle audit timeout", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (
            err: { killed: boolean; signal: string },
            result: null,
          ) => void,
        ) => {
          callback({ killed: true, signal: "SIGTERM" }, null);
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.auditCompleted).toBe(false);
      expect(result.auditInfo.auditError).toContain("timed out");
      expect(result.status).toBe("NEED_MORE_INFO");
    });

    it("should handle audit command failure with no output", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: { stderr: string }, result: null) => void,
        ) => {
          callback({ stderr: "npm ERR! audit command failed" }, null);
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.auditInfo.auditCompleted).toBe(false);
      expect(result.auditInfo.auditError).toContain("npm ERR!");
      expect(result.status).toBe("NEED_MORE_INFO");
      expect(result.recommendations).toContainEqual(
        expect.stringContaining("Check that"),
      );
    });

    it("should handle malformed JSON output", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: "not valid json {{{" });
        },
      );

      const result = await assessor.assess(mockContext);

      // Should still complete but with empty results
      expect(result.auditInfo.auditCompleted).toBe(true);
      expect(result.totalAdvisories).toBe(0);
      expect(result.findings).toHaveLength(0);
    });
  });

  // ============================================
  // Section 9: Recommendations Generation
  // ============================================

  describe("recommendations", () => {
    beforeEach(() => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );
    });

    it("should recommend npm audit fix for npm projects", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {
                pkg: {
                  severity: "high",
                  via: ["issue"],
                  nodes: ["pkg"],
                  fixAvailable: true,
                },
              },
              metadata: {
                vulnerabilities: { critical: 0, high: 1, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.recommendations).toContainEqual(
        expect.stringContaining("npm audit fix"),
      );
    });

    it("should include critical/high vulnerability details in recommendations", async () => {
      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, {
            stdout: JSON.stringify({
              vulnerabilities: {
                dangerous: {
                  severity: "critical",
                  via: [{ title: "Remote Code Execution" }],
                  nodes: ["dangerous"],
                  fixAvailable: false,
                },
              },
              metadata: {
                vulnerabilities: { critical: 1, high: 0, moderate: 0, low: 0 },
              },
            }),
          });
        },
      );

      const result = await assessor.assess(mockContext);

      expect(result.recommendations).toContainEqual(
        expect.stringContaining("CRITICAL"),
      );
      expect(result.recommendations).toContainEqual(
        expect.stringContaining("dangerous"),
      );
    });
  });

  // ============================================
  // Section 10: Test Count
  // ============================================

  describe("test count", () => {
    it("should count 1 test for successful audit", async () => {
      mockContext.sourceCodePath = "/test/project";
      mockExistsSync.mockImplementation((filePath: string) =>
        filePath.endsWith("package-lock.json"),
      );

      mockExec.mockImplementation(
        (
          _cmd: string,
          _opts: unknown,
          callback: (err: null, result: { stdout: string }) => void,
        ) => {
          callback(null, { stdout: '{"vulnerabilities":{}}' });
        },
      );

      await assessor.assess(mockContext);

      expect(assessor.getTestCount()).toBe(1);
    });

    it("should count 0 tests when skipped", async () => {
      mockContext.sourceCodePath = undefined;

      await assessor.assess(mockContext);

      expect(assessor.getTestCount()).toBe(0);
    });
  });
});
